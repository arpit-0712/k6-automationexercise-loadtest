name: k6 Load Test

on:
  workflow_dispatch:      # run manually from GitHub UI
    inputs:
      parallel_instances:
        description: 'Number of parallel instances to run'
        required: false
        default: '4'
        type: choice
        options:
          - '2'
          - '4'
          - '8'
  push:
    branches:
      - main

jobs:
  k6-load-test-parallel:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        # Number of parallel instances - can be adjusted
        instance: [1, 2, 3, 4]  # Run 4 instances in parallel by default
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install k6
        uses: grafana/setup-k6-action@v1

      - name: Verify k6 script exists
        run: |
          if [ ! -f automationexecise-loadtest.js ]; then
            echo "ERROR: automationexecise-loadtest.js not found!"
            ls -la *.js || echo "No JS files found"
            exit 1
          fi
          echo "âœ“ k6 script found: automationexecise-loadtest.js"

      - name: Run k6 load test (Instance ${{ matrix.instance }})
        continue-on-error: true
        id: k6_test
        run: |
          mkdir -p reports/instance-${{ matrix.instance }}
          # Calculate execution segment for this instance (4 instances total)
          TOTAL_INSTANCES=4
          CURRENT_INSTANCE=${{ matrix.instance }}
          SEGMENT_START=$(( (CURRENT_INSTANCE - 1) * 100 / TOTAL_INSTANCES ))
          SEGMENT_END=$(( CURRENT_INSTANCE * 100 / TOTAL_INSTANCES ))
          
          echo "Running instance $CURRENT_INSTANCE of $TOTAL_INSTANCES"
          echo "Execution segment: $SEGMENT_START%-$SEGMENT_END%"
          
          k6 run automationexecise-loadtest.js \
            --execution-segment "$SEGMENT_START%-$SEGMENT_END%" \
            --execution-segment-sequence "$CURRENT_INSTANCE/$TOTAL_INSTANCES" \
            --out json=reports/instance-${{ matrix.instance }}/k6-result.json \
            --summary-export=reports/instance-${{ matrix.instance }}/summary.json || {
            EXIT_CODE=$?
            echo "k6_exit_code=$EXIT_CODE" >> $GITHUB_OUTPUT
            echo "k6 test completed with exit code $EXIT_CODE"
            # Still try to upload reports even if k6 failed
            if [ -f reports/instance-${{ matrix.instance }}/summary.json ]; then
              echo "Summary file exists, will be uploaded"
            fi
          }

      - name: Upload instance reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: k6-reports-instance-${{ matrix.instance }}
          path: reports/instance-${{ matrix.instance }}/
          retention-days: 7

  merge-reports:
    needs: k6-load-test-parallel
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Download all instance reports
        uses: actions/download-artifact@v4
        with:
          path: reports/

      - name: Debug - List downloaded files
        if: always()
        run: |
          echo "=== Directory structure ==="
          find reports -type f -name "*.json" 2>/dev/null | head -20 || echo "No JSON files found"
          echo ""
          echo "=== All files in reports ==="
          find reports -type f 2>/dev/null | head -20 || echo "No files found"
          echo ""
          echo "=== Directory listing ==="
          ls -la reports/ || echo "reports directory not found"
          echo ""
          echo "=== Flattening artifact structure ==="
          # GitHub Actions downloads artifacts into subdirectories, flatten them
          if [ -d reports/k6-reports-instance-1 ]; then
            mkdir -p reports/flattened
            for dir in reports/k6-reports-instance-*/; do
              if [ -d "$dir" ]; then
                INSTANCE_NUM=$(basename "$dir" | grep -o '[0-9]\+')
                echo "Processing instance $INSTANCE_NUM from $dir"
                # Copy files, handling nested structure
                find "$dir" -type f -name "*.json" -exec cp {} reports/flattened/instance-${INSTANCE_NUM}-$(basename {}) \;
                # Also try direct copy
                cp -r "$dir"* reports/flattened/ 2>/dev/null || true
              fi
            done
            # Update reports path
            if [ -d reports/flattened ]; then
              cp -r reports/flattened/* reports/ 2>/dev/null || true
            fi
          fi

      - name: Merge k6 reports
        continue-on-error: true
        run: |
          mkdir -p reports/merged
          python3 << 'EOF'
          import json
          import os
          import sys
          import glob
          
          # Try multiple patterns to find summary files
          # GitHub Actions downloads artifacts into subdirectories matching artifact name
          patterns = [
              'reports/k6-reports-instance-*/instance-*/summary.json',
              'reports/k6-reports-instance-*/summary.json',
              'reports/**/instance-*/summary.json',
              'reports/**/summary.json',
              'reports/*/summary.json',
              'reports/summary.json'
          ]
          
          summary_files = []
          for pattern in patterns:
              found = glob.glob(pattern, recursive=True)
              if found:
                  summary_files.extend(found)
          
          # Remove duplicates and sort
          summary_files = sorted(list(set(summary_files)))
          
          if not summary_files:
              print("ERROR: No summary files found")
              print("Searched patterns:")
              for pattern in patterns:
                  print(f"  - {pattern}")
              print("\nAvailable files:")
              for root, dirs, files in os.walk('reports'):
                  for file in files:
                      print(f"  {os.path.join(root, file)}")
              # Don't exit with error, just create empty report
              print("\nCreating empty merged report...")
              merged_summary = {
                  'state': {'testRunDurationMs': 0},
                  'metrics': {},
                  'root_group': {'duration': 0, 'thresholds': {}},
                  'error': 'No summary files found from parallel instances'
              }
              with open('reports/merged/summary.json', 'w') as f:
                  json.dump(merged_summary, f, indent=2)
              sys.exit(0)
          
          print(f"Found {len(summary_files)} instance reports to merge:")
          for f in summary_files:
              print(f"  - {f}")
          
          # Initialize merged data structure
          merged_metrics = {}
          merged_state = {}
          merged_root_group = {}
          
          # Aggregate metrics from all instances
          for summary_file in summary_files:
              try:
                  with open(summary_file, 'r') as f:
                      data = json.load(f)
              except Exception as e:
                  print(f"Warning: Failed to parse {summary_file}: {e}")
                  continue
              
              # Merge metrics
              for metric_name, metric_data in data.get('metrics', {}).items():
                  if metric_name not in merged_metrics:
                      merged_metrics[metric_name] = {
                          'values': {
                              'count': 0,
                              'rate': 0,
                              'avg': 0,
                              'min': float('inf'),
                              'max': 0,
                              'p90': 0,
                              'p95': 0,
                              'p99': 0
                          }
                      }
                  
                  values = metric_data.get('values', {})
                  merged_values = merged_metrics[metric_name]['values']
                  
                  # Aggregate counts and rates
                  merged_values['count'] += values.get('count', 0)
                  merged_values['rate'] += values.get('rate', 0)
                  
                  # For averages, we'll recalculate later
                  if 'avg' in values:
                      merged_values['avg'] = max(merged_values.get('avg', 0), values.get('avg', 0))
                  
                  # Min/Max
                  if 'min' in values:
                      merged_values['min'] = min(merged_values.get('min', float('inf')), values.get('min', float('inf')))
                  if 'max' in values:
                      merged_values['max'] = max(merged_values.get('max', 0), values.get('max', 0))
                  
                  # Percentiles (take max across instances)
                  for p in ['p90', 'p95', 'p99']:
                      if p in values:
                          merged_values[p] = max(merged_values.get(p, 0), values.get(p, 0))
          
          # Create merged summary
          merged_summary = {
              'state': {
                  'testRunDurationMs': 0
              },
              'metrics': merged_metrics,
              'root_group': {
                  'duration': 0,
                  'thresholds': {}
              }
          }
          
          # Calculate total duration from first instance
          if summary_files:
              with open(summary_files[0], 'r') as f:
                  first_data = json.load(f)
                  merged_summary['state']['testRunDurationMs'] = first_data.get('state', {}).get('testRunDurationMs', 0)
                  merged_summary['root_group']['duration'] = first_data.get('root_group', {}).get('duration', 0)
          
          # Save merged summary
          with open('reports/merged/summary.json', 'w') as f:
              json.dump(merged_summary, f, indent=2)
          
          print("Successfully merged all instance reports")
          EOF

      - name: Generate combined HTML report
        continue-on-error: true
        if: always()
        run: |
          if [ -f reports/merged/summary.json ]; then
            python3 generate_html_report.py reports/merged/summary.json reports/merged/k6-report.html || echo "HTML generation failed, but continuing..."
            echo "Combined HTML report generation attempted"
          else
            echo "Warning: merged summary.json not found, skipping HTML generation"
          fi

      - name: Display test summary
        if: always()
        run: |
          if [ -f reports/merged/summary.json ]; then
            echo "## k6 Load Test Summary (Parallel Execution)" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Total Instances:** 4" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            cat reports/merged/summary.json | jq '.metrics | {http_reqs: .http_reqs.values, http_req_duration: .http_req_duration.values, http_req_failed: .http_req_failed.values}' >> $GITHUB_STEP_SUMMARY || cat reports/merged/summary.json >> $GITHUB_STEP_SUMMARY
          fi
          if [ -f reports/merged/k6-report.html ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "## ðŸ“Š Combined HTML Report" >> $GITHUB_STEP_SUMMARY
            echo "Download the merged HTML report from the artifacts to view detailed test results from all parallel instances." >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload merged reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: k6-reports-merged
          path: reports/merged/
          retention-days: 30